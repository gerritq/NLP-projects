{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyPckndRDI7HGjFmYO1HgctP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# RNN to Predict the Language of a Word\n","\n","For an assignment, I implement a character-level vanilla RNN to predict whether a single word is German or English."],"metadata":{"id":"raV1dQHHdyH1"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ehcKtK1xU59Z","executionInfo":{"status":"ok","timestamp":1715649548837,"user_tz":240,"elapsed":12982,"user":{"displayName":"Gerrit Quaremba","userId":"00513744430966393176"}},"outputId":"1e073b31-83da-4c1f-835c-ac381fd60b34"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# Load colab packages\n","from google.colab import files\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from torch.nn import functional as F\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import nltk\n","nltk.download('words')\n","import random"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qcv1tF-sVvuO","executionInfo":{"status":"ok","timestamp":1715649557328,"user_tz":240,"elapsed":4510,"user":{"displayName":"Gerrit Quaremba","userId":"00513744430966393176"}},"outputId":"431473eb-6758-43eb-d014-030ab7b35e49"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package words to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/words.zip.\n"]}]},{"cell_type":"markdown","source":["# Load and prep data"],"metadata":{"id":"FhW_pHIf8qky"}},{"cell_type":"code","source":["from nltk.corpus import words\n","\n","# Load data\n","def load_data():\n","  '''Wrapper to load data'''\n","\n","  random.seed(42)\n","\n","  # Select words per language\n","\n","  n=25000\n","\n","  # Sample English words\n","  english_words = words.words()\n","  english_words = random.sample(english_words, n)\n","  labels_english = [0] * len(english_words)\n","\n","  # Sample German words\n","  with open('/content/drive/My Drive/08_NN_Kaparthy/RNN/data/wordlist-german.txt', 'r', encoding='utf-8') as f:\n","    words_german = f.read().strip().split('\\n')\n","\n","  words_german = random.sample(words_german, n)\n","  labels_german = [1] * len(words_german)\n","\n","  # Combine and shuffle words\n","  all_words = english_words + words_german\n","  all_labels = labels_english + labels_german\n","\n","  shuffled_indices = list(range(len(all_words)))\n","  random.shuffle(shuffled_indices)\n","  all_words = [all_words[i] for i in shuffled_indices]\n","  all_labels = [all_labels[i] for i in shuffled_indices]\n","\n","  return all_words, all_labels"],"metadata":{"id":"V6Txxby3pOch"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Num words and unique chars\n","words, labels = load_data()\n","\n","print(\"Num words: \", len(words))\n","print(\"Show distribution: \", np.unique(labels, return_counts=True))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3cRA0cylX1kN","executionInfo":{"status":"ok","timestamp":1715649653340,"user_tz":240,"elapsed":475,"user":{"displayName":"Gerrit Quaremba","userId":"00513744430966393176"}},"outputId":"2b273bd5-1a44-492f-a717-4dd5df3cbdea"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Num words:  50000\n","Show distribution:  (array([0, 1]), array([25000, 25000]))\n"]}]},{"cell_type":"code","source":["# Create char list\n","chars = sorted(list(set(''.join(words))))\n","vocab_size = len(chars)\n","print(\"Unique sorted chars: \",''.join(chars))\n","print('Unique chars: ', vocab_size)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R917BgcDWLgJ","executionInfo":{"status":"ok","timestamp":1715649654032,"user_tz":240,"elapsed":3,"user":{"displayName":"Gerrit Quaremba","userId":"00513744430966393176"}},"outputId":"031e02ca-9380-4d66-d98a-be180389bdcb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Unique sorted chars:  ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyzÄÅÖÜßáäèéêëöü\n","Unique chars:  65\n"]}]},{"cell_type":"code","source":["# tokenise = convert raw chars to seq of integers\n","stoi = {ch:i for i,ch in enumerate(chars)}\n","# function to take str/int and output int/str\n","encode = lambda s: torch.tensor([stoi[c] for c in s], dtype=torch.long)"],"metadata":{"id":"xc6nQIpwWlgU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train test sampels\n","n=int(len(words)*.8)\n","words_train = words[:n]\n","labels_train = labels[:n]\n","words_test = words[n:]\n","labels_test = labels[n:]\n","\n","print('len train', len(words_train))\n","print('len test', len(words_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mh4nEmcasIl7","executionInfo":{"status":"ok","timestamp":1715649660468,"user_tz":240,"elapsed":419,"user":{"displayName":"Gerrit Quaremba","userId":"00513744430966393176"}},"outputId":"65a8b2b7-5bc0-4298-8439-07d798dfc743"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["len train 40000\n","len test 10000\n"]}]},{"cell_type":"code","source":["# Check some words\n","print(words_train[:5], labels_train[:5])\n","print(np.unique(labels_train, return_counts=True))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RESU80LKse7v","executionInfo":{"status":"ok","timestamp":1715649683947,"user_tz":240,"elapsed":3,"user":{"displayName":"Gerrit Quaremba","userId":"00513744430966393176"}},"outputId":"57429d16-abf4-481c-e319-7baa4604e1c9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['Geschichtswissenschaften', 'Faktorausstattung', 'Spareinlagenbücher', 'Bemba', 'perceivance'] [1, 1, 1, 0, 0]\n","(array([0, 1]), array([20045, 19955]))\n"]}]},{"cell_type":"markdown","source":["This is a simple RNN with one cell.\n","\n","Model can be advanced on multiple ends:\n","\n","*   More cells\n","*   LSTM, GRU cells (preferably for longer networks)\n","*   Adding an embedding table as trainable params\n","*   Adding dropout\n","\n"],"metadata":{"id":"Ni3CaWtof01r"}},{"cell_type":"code","source":["# Define model\n","class RNN(nn.Module):\n","\n","    def __init__(self, input_size, hidden_size, output_size):\n","        super().__init__()\n","\n","        self.hidden_size = hidden_size\n","\n","        self.embedding_table = nn.Embedding(input_size, hidden_size)\n","        #self.charToHidden = nn.Linear(input_size, hidden_size)\n","        self.hiddenToHidden = nn.Linear(hidden_size, hidden_size)\n","        self.hiddenToOutput = nn.Linear(hidden_size, output_size)\n","\n","    def forward(self, input, hidden):\n","        #emb = self.charToHidden(input) # 1, hidden_size\n","        emb = self.embedding_table(input) # 1, hidden_size\n","        hidden = self.hiddenToHidden(hidden) # 1, hidden_size x hidden_size, hidden_size = 1, hidden_size\n","        new_hidden = torch.tanh(emb + hidden) # 1, hidden_size\n","        logits = self.hiddenToOutput(new_hidden) # 1, output_size\n","        return logits, new_hidden # 1, output_size; 1 x 128\n","\n","    def initHidden(self):\n","        return torch.zeros(1, self.hidden_size)"],"metadata":{"id":"TEuVxvxdiCgh","executionInfo":{"status":"ok","timestamp":1715652870577,"user_tz":240,"elapsed":326,"user":{"displayName":"Gerrit Quaremba","userId":"00513744430966393176"}}},"execution_count":64,"outputs":[]},{"cell_type":"code","source":["n_hidden = 128\n","# input size = vocab size due to one-hot\n","rnn = RNN(vocab_size, n_hidden, 2)"],"metadata":{"id":"wy62vkZ4ABal","executionInfo":{"status":"ok","timestamp":1715652872942,"user_tz":240,"elapsed":329,"user":{"displayName":"Gerrit Quaremba","userId":"00513744430966393176"}}},"execution_count":65,"outputs":[]},{"cell_type":"code","source":["# Example word and output\n","hidden = torch.zeros(1, n_hidden)\n","\n","output, next_hidden = rnn(torch.tensor([1]), hidden)\n","print(output)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fSZET87MiGfj","executionInfo":{"status":"ok","timestamp":1715652875646,"user_tz":240,"elapsed":319,"user":{"displayName":"Gerrit Quaremba","userId":"00513744430966393176"}},"outputId":"0b31e418-9e16-4ad1-f03d-c93848b0d59f"},"execution_count":66,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 0.6193, -0.3875]], grad_fn=<AddmmBackward0>)\n"]}]},{"cell_type":"markdown","source":["# Training\n"],"metadata":{"id":"Y6r5hR4cmZ7C"}},{"cell_type":"markdown","source":["Function to sample an encoded word with label either training or test data."],"metadata":{"id":"72uJv--DglZ4"}},{"cell_type":"code","source":["def random_sample(data:str, word=None):\n","    '''''Sample a single word, label, and one-hot representation from either training or test data'''\n","\n","    # Sample from the training set\n","    if data == 'train':\n","      idx = torch.randint(len(words_train), size=(1,))\n","      word = words_train[idx]\n","      word_encoded = encode(word)\n","      label = torch.tensor([labels_train[idx]], dtype=torch.long)\n","\n","      return word_encoded, label\n","\n","    # Return above for test word\n","    else:\n","      word_encoded = encode(word)\n","      label = torch.tensor([labels_test[words_test.index(word)]], dtype=torch.long)\n","\n","      return word_encoded, label"],"metadata":{"id":"Zlf-dKFZjIyF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Example for test set\n","random_sample('test', words_test[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CoG3A7KVeSyA","executionInfo":{"status":"ok","timestamp":1715649712020,"user_tz":240,"elapsed":319,"user":{"displayName":"Gerrit Quaremba","userId":"00513744430966393176"}},"outputId":"a5054353-cd61-484d-d160-e6ac474f4f0e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([38, 40, 43, 36, 34, 39]), tensor([0]))"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["# Initiate optmizer; can play around, tendency for higher LR as network is small\n","learning_rate=.0001\n","optimizer = torch.optim.Adam(rnn.parameters(), lr=learning_rate)"],"metadata":{"id":"ZWfeZ3yOOCun"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Params\n","n_iters = len(words_train) *2 # Run the training data twice\n","eval_at = 5000\n","loss_at = 5000\n","losses=[]\n","losses_at=[]\n","\n","rnn.train()\n","\n","# Run training loop\n","for iter in range(0, n_iters + 1):\n","\n","    # Get training example\n","    word_encoded, label = random_sample('train')\n","\n","    # Training\n","    hidden = rnn.initHidden()\n","\n","    # Loop chars\n","    for i, charint in enumerate(word_encoded):\n","        output, hidden = rnn(charint, hidden)\n","\n","    loss = F.cross_entropy(output, label)\n","    losses.append(loss.item())\n","\n","    optimizer.zero_grad(set_to_none=True)\n","    # backprop and step\n","    loss.backward()\n","    optimizer.step()\n","\n","    if iter % eval_at == 0:\n","      print(f\"Iteration {iter}/{n_iters} Avg loss: {sum(losses)/eval_at:.5f}\")\n","      losses = []\n","\n","    if iter % loss_at == 0 or iter==0:\n","        losses_at.append(loss.item()/loss_at)\n","        losses_at=[]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m2O-NE_xjYi0","executionInfo":{"status":"ok","timestamp":1715650147886,"user_tz":240,"elapsed":377891,"user":{"displayName":"Gerrit Quaremba","userId":"00513744430966393176"}},"outputId":"7ff14293-abc1-4826-f73f-810f3c6de180"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Iteration 0/80000 Avg loss: 0.00013\n","Iteration 5000/80000 Avg loss: 0.44257\n","Iteration 10000/80000 Avg loss: 0.23301\n","Iteration 15000/80000 Avg loss: 0.14771\n","Iteration 20000/80000 Avg loss: 0.13226\n","Iteration 25000/80000 Avg loss: 0.10778\n","Iteration 30000/80000 Avg loss: 0.09797\n","Iteration 35000/80000 Avg loss: 0.08328\n","Iteration 40000/80000 Avg loss: 0.09000\n","Iteration 45000/80000 Avg loss: 0.08997\n","Iteration 50000/80000 Avg loss: 0.08720\n","Iteration 55000/80000 Avg loss: 0.08172\n","Iteration 60000/80000 Avg loss: 0.07858\n","Iteration 65000/80000 Avg loss: 0.07834\n","Iteration 70000/80000 Avg loss: 0.07464\n","Iteration 75000/80000 Avg loss: 0.06861\n","Iteration 80000/80000 Avg loss: 0.07114\n"]}]},{"cell_type":"markdown","source":["## Training and Test Performance\n"],"metadata":{"id":"AYQdxs3YxqlV"}},{"cell_type":"code","source":["# Eval\n","def evaluate(word_encoded, label):\n","\n","    rnn.eval()\n","\n","    with torch.no_grad():\n","      hidden = rnn.initHidden()\n","\n","      for charint in word_encoded:\n","          output, hidden = rnn(charint, hidden)\n","          pred = torch.argmax(output, dim=1)\n","      return int(pred == label)"],"metadata":{"id":"Z8xhhZmyUWZ3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Training Set Accuracy"],"metadata":{"id":"6yNmyRwanwtQ"}},{"cell_type":"code","source":["tr_n = 500\n","tr_acc = torch.tensor([0], dtype=torch.float)\n","\n","for i in range(0, tr_n):\n","    word_encoded, label = random_sample('train')\n","    tr_acc += evaluate(word_encoded, label)\n","\n","print(\"Train acc \", tr_acc/tr_n)"],"metadata":{"id":"pLPtHi37yzto","executionInfo":{"status":"ok","timestamp":1715650269999,"user_tz":240,"elapsed":1072,"user":{"displayName":"Gerrit Quaremba","userId":"00513744430966393176"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"be1a1c65-22a3-4575-a9a4-b65c7ff18027"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Train acc  tensor([0.9840])\n"]}]},{"cell_type":"markdown","source":["## Test Set Accuracy"],"metadata":{"id":"drYTxHz5ohrE"}},{"cell_type":"code","source":["te_acc = torch.tensor([0], dtype=torch.float)\n","\n","for word in words_test:\n","    word_encoded, label = random_sample('test', word)\n","    te_acc += evaluate(word_encoded, label)\n","\n","print(\"Test acc \", te_acc/len(words_test))"],"metadata":{"id":"nEmRe9k5rkQA","executionInfo":{"status":"ok","timestamp":1715650286587,"user_tz":240,"elapsed":13900,"user":{"displayName":"Gerrit Quaremba","userId":"00513744430966393176"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9179c6b0-19c1-4091-83fa-f4ce8d6d2a2c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test acc  tensor([0.9686])\n"]}]},{"cell_type":"code","source":["def predict_language(word: str):\n","  word_encoded = encode(word)\n","  rnn.eval()\n","  with torch.no_grad():\n","    hidden = rnn.initHidden()\n","    for charint in word_encoded:\n","      output, hidden = rnn(charint, hidden)\n","\n","    probs = F.softmax(output, dim=1)\n","    pred = torch.argmax(output, dim=1)\n","\n","  return f\"German {probs[0][pred].item()*100:.0f}%\" if int(pred) == 1 else f\"English {probs[0][pred].item()*100:.0f}%\""],"metadata":{"id":"9tkaWHDWo4Q-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ood = [\"Ich\", \"liebe\", \"Sprachverarbeitung\"]\n","for word in ood:\n","  print(word, \"==>\", predict_language(word), \"Out of distribution? \", word not in words)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EpdhHAQfpCd6","executionInfo":{"status":"ok","timestamp":1715651317476,"user_tz":240,"elapsed":8,"user":{"displayName":"Gerrit Quaremba","userId":"00513744430966393176"}},"outputId":"ce1a9ab9-a9c2-4693-8831-bffc1a08c7a3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Ich ==> German 76% Out of distribution?  True\n","liebe ==> German 59% Out of distribution?  True\n","Sprachverarbeitung ==> German 100% Out of distribution?  True\n"]}]},{"cell_type":"code","source":["ood = [\"I\", \"love\", \"naturallanguage\"]\n","for word in ood:\n","  print(word, \"==>\", predict_language(word), \"Out of distribution? \", word not in words)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N9CHlNZGyEnA","executionInfo":{"status":"ok","timestamp":1715651352415,"user_tz":240,"elapsed":4,"user":{"displayName":"Gerrit Quaremba","userId":"00513744430966393176"}},"outputId":"fe726444-9929-49d4-b18a-be94911cfefb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["I ==> German 98% Out of distribution?  True\n","love ==> English 99% Out of distribution?  False\n","naturallanguage ==> English 51% Out of distribution?  True\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"S0SIMlzsydlK"},"execution_count":null,"outputs":[]}]}